from __future__ import print_function

import numpy as np
import cv2 as cv
import sys
import streamlit as st
import tempfile
import os
import pickle
import matplotlib.pyplot as plt
# import torch
import pandas as pd

sys.path.append("./services") 
from semantic_keypoint_detection.Superpoint import SuperPointNet, SuperPointFrontend
from io import BytesIO
from PIL import Image, ImageOps, ImageDraw
from scipy.spatial.distance import cdist
# from rembg import remove
from streamlit_drawable_canvas import st_canvas

st.set_page_config(
    page_title="üéàHoang Hao's Applications",
    page_icon=Image.open("./images/Logo/logo_welcome.png"),
    layout="wide",
    initial_sidebar_state="expanded",
)
st.title('üéàSemantic Keypoint Detection')


sift = cv.SIFT_create()


orb = cv.ORB_create()


def SIFT_result(image):
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)
    keypoints, descriptors = sift.detectAndCompute(gray, None)

    output_image = cv.drawKeypoints(image, keypoints, None, color=(0, 255, 0), flags=0)
    return keypoints, descriptors, output_image

def ORB_result(image):
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)
    keypoints, descriptors = orb.detectAndCompute(gray, None)
    output_image = cv.drawKeypoints(image, keypoints, None, color=(0, 255, 0), flags=0)
    return keypoints, descriptors, output_image


def load_image_dataset(path):
    path_dataset = './images/SIFT_SURF_ORB/synthetic_shapes_datasets/synthetic_shapes_datasets/'
    path_image = path_dataset + path + "/" + "images"
    path_label = path_dataset + path + "/" + "points"
    lst_all_image = os.listdir(path_image)
    lst_all_label = os.listdir(path_label)
    lst_image = []
    lst_label = []
    for i in range(len(lst_all_image)):
        path_image_cur = path_image + "/" + str(i) + ".png"
        
        image = cv.imread(path_image_cur)
        lst_image.append(image)
        
        path_label_cur = path_label + "/" + str(i) + ".npy"
        label = np.load(path_label_cur)
        lst_label.append(label)
    return lst_image, lst_label


def calculate_precision(predicted_keypoints, groundtruth_keypoints, threshold=4):
    true_positive = 0
    predicted_points  = np.array([kp.pt for kp in predicted_keypoints])
    groundtruth_points = np.array(groundtruth_keypoints)
    groundtruth_points = groundtruth_points[:, [1, 0]]
   # N·∫øu kh√¥ng c√≥ predicted ho·∫∑c ground truth keypoints
    if len(predicted_points) == 0 or len(groundtruth_points) == 0:
        return 0.0
    
    # T√≠nh kho·∫£ng c√°ch Euclidean gi·ªØa predicted v√† groundtruth
    distances = cdist(predicted_points, groundtruth_points, metric='euclidean')
    
    # Ki·ªÉm tra c√°c predicted keypoint c√≥ keypoint ground truth n√†o trong ph·∫°m vi <= threshold
    matched_predictions = np.min(distances, axis=1) <= threshold
    
    # T√≠nh True Positive (TP) v√† False Positive (FP)
    TP = np.sum(matched_predictions)  # S·ªë l∆∞·ª£ng predicted ƒë√∫ng
    FP = len(predicted_keypoints) - TP  # S·ªë l∆∞·ª£ng predicted sai

    # T√≠nh Precision
    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0
    
    return precision

def calculate_recall(predicted_keypoints, groundtruth_keypoints, threshold=4):
    true_positive = 0
    predicted_points  = np.array([kp.pt for kp in predicted_keypoints])
    groundtruth_points = np.array(groundtruth_keypoints)
    groundtruth_points = groundtruth_points[:, [1, 0]]
   # N·∫øu kh√¥ng c√≥ predicted ho·∫∑c ground truth keypoints
    if len(predicted_points) == 0 or len(groundtruth_points) == 0:
        return 0.0
    
    # T√≠nh kho·∫£ng c√°ch Euclidean gi·ªØa predicted v√† groundtruth
    distances = cdist(predicted_points, groundtruth_points, metric='euclidean')
    
    # Ki·ªÉm tra c√°c predicted keypoint c√≥ keypoint ground truth n√†o trong ph·∫°m vi <= threshold
    matched_predictions = np.min(distances, axis=1) <= threshold
    
    # T√≠nh True Positive (TP) v√† False Positive (FP)
    TP = np.sum(matched_predictions)  
    FP = len(predicted_keypoints) - TP  

    matched_groundtruth = np.min(distances, axis=0) <= threshold
    
    # False Negative (FN): ground truth kh√¥ng c√≥ predicted kh·ªõp
    FN = np.sum(~matched_groundtruth)
    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0
    
    return recall

def draw_keypoints(image, keypoints):
    for keypoint in keypoints:
        x, y = int(keypoint[1]), int(keypoint[0])
        cv.circle(image, (x, y), radius=5, color=(0, 255, 0), thickness=2)  # M√†u xanh l√°
    return image

def plot_metric_precision(precision_SIFT, precision_ORB, c):
    categories = ['checkerboard', 'cube', 'ellipses', 'lines', 'multiple_polygons', 'polygon', 'star', 'stripes']
    values1 = np.array(precision_SIFT)
    values2 = np.array(precision_ORB)
    
    data = {
            'Shapes': categories,
            'Precision of ORB': values2,
            'Precision of SIFT': values1,
        }

    df = pd.DataFrame(data)
    c.bar_chart(df, x = "Shapes", stack = False, horizontal=True, color = ["#19c9fe", "#fcc200"])
    
def plot_metric_recall(recall_SIFT, recall_ORB, c):
    categories = ['checkerboard', 'cube', 'ellipses', 'lines', 'multiple_polygons', 'polygon', 'star', 'stripes']
    values1 = np.array(recall_SIFT)
    values2 = np.array(recall_ORB)
    
    data = {
        'Shapes': categories,
        'Recall of ORB': values2,
        'Recall of SIFT': values1,
    }

    df = pd.DataFrame(data)
    c.bar_chart(df, x = "Shapes", stack = False, horizontal=True, color = ["#19c9fe", "#fcc200"])


def plot_metric():
    precision_SIFT = []
    precision_ORB = []
    recall_SIFT = []
    recall_ORB = []
    with open('./data_processed/Semantic_Keypoint_Detection/precision_SIFT.pkl', 'rb') as file:
        precision_SIFT = pickle.load(file)
    with open('./data_processed/Semantic_Keypoint_Detection/precision_ORB.pkl', 'rb') as file:
        precision_ORB = pickle.load(file)
    with open('./data_processed/Semantic_Keypoint_Detection/recall_SIFT.pkl', 'rb') as file:
        recall_SIFT = pickle.load(file)
    with open('./data_processed/Semantic_Keypoint_Detection/recall_ORB.pkl', 'rb') as file:
        recall_ORB = pickle.load(file)

    c1, c2 = st.columns(2)
    plot_metric_precision(precision_SIFT, precision_ORB, c1)
    plot_metric_recall(recall_SIFT, recall_ORB, c2)

def calculate_Precision_and_Recall():
    lst_name_dataset = ['draw_checkerboard', 'draw_cube', 'draw_ellipses', 'draw_lines', 'draw_multiple_polygons',
                        'draw_polygon', 'draw_star', 'draw_stripes']
    lst_image = []
    lst_label = []
    for i in range(len(lst_name_dataset)):
        image, label = load_image_dataset(lst_name_dataset[i])
        lst_image.append(image)
        lst_label.append(label)
    # SIFT
    lst_precision = []
    lst_recall = []
    average_precision = []
    average_recall = []
    
    # ORB
    lst_precision_ORB = []
    lst_recall_ORB = []
    average_precision_ORB = []
    average_recall_ORB = []
    for i in range(len(lst_image)):
        precision = []
        recall = []
        
        precision_ORB = []
        recall_ORB = []
        for j in range(len(lst_image[i])):
            keypoints, _, _ = SIFT_result(lst_image[i][j])
            
            keypoints_ORB, _, _ = ORB_result(lst_image[i][j])
            
            precision.append(calculate_precision(keypoints, lst_label[i][j], threshold=4))
            recall.append(calculate_recall(keypoints, lst_label[i][j], threshold=4))
            
            precision_ORB.append(calculate_precision(keypoints_ORB, lst_label[i][j], threshold=4))
            recall_ORB.append(calculate_recall(keypoints_ORB, lst_label[i][j], threshold=4))
        lst_precision.append(precision)
        lst_recall.append(recall)
        
        lst_precision_ORB.append(precision_ORB)
        lst_recall_ORB.append(recall_ORB)
    for i in range(len(lst_precision)):
        average_precision.append(sum(lst_precision[i]) / len(lst_precision[i]))
        average_recall.append(sum(lst_recall[i]) / len(lst_recall[i]))
        
        average_precision_ORB.append(sum(lst_precision_ORB[i]) / len(lst_precision_ORB[i]))
        average_recall_ORB.append(sum(lst_recall_ORB[i]) / len(lst_recall_ORB[i]))
    pickle_file_pre_SIFT = './data_processed/Semantic_Keypoint_Detection/precision_SIFT.pkl'
    with open(pickle_file_pre_SIFT, 'wb') as file:
        pickle.dump(average_precision, file)
        
    pickle_file_recall_SIFT = './data_processed/Semantic_Keypoint_Detection/recall_SIFT.pkl'
    with open(pickle_file_recall_SIFT, 'wb') as file:
        pickle.dump(average_recall, file)
        
    pickle_file_pre_ORB = './data_processed/Semantic_Keypoint_Detection/precision_ORB.pkl'
    with open(pickle_file_pre_ORB, 'wb') as file:
        pickle.dump(average_precision_ORB, file)   
        
    pickle_file_recall_ORB = './data_processed/Semantic_Keypoint_Detection/recall_ORB.pkl'
    with open(pickle_file_recall_ORB, 'wb') as file:
        pickle.dump(average_recall_ORB, file)   
        
    # plot_metric(average_precision, average_recall)
    # print(lst_recall)
    

def get_image_and_label():
    lst_name_dataset = ['draw_checkerboard', 'draw_cube', 'draw_ellipses', 'draw_lines', 'draw_multiple_polygons',
                        'draw_polygon', 'draw_star', 'draw_stripes']
    lst_image = []
    lst_label = []
    for i in range(len(lst_name_dataset)):
        image, label = load_image_dataset(lst_name_dataset[i])
        lst_image.append(image)
        lst_label.append(label)
    return lst_image, lst_label
    # pickle_lst_image = './data_processed/Semantic_Keypoint_Detection/lst_image.pkl'
    # with open(pickle_lst_image, 'wb') as file:
    #     pickle.dump(lst_image, file)
    # pickle_lst_label = './data_processed/Semantic_Keypoint_Detection/lst_label.pkl'
    # with open(pickle_lst_label, 'wb') as file:
    #     pickle.dump(lst_label, file)
    # lst_image = []
    # lst_label = []
    # with open('./data_processed/Semantic_Keypoint_Detection/lst_image.pkl', 'rb') as file:
    #     lst_image = pickle.load(file)
    # with open('./data_processed/Semantic_Keypoint_Detection/lst_label.pkl', 'rb') as file:
    #     lst_label = pickle.load(file)
    # draw_keypoints(lst_image[7][10], lst_label[7][10])
    # 0 8, 1 10, 2 10, 3 11, 4 11, 5 12, 6 10, 
    

def rotate_image(image, angle):
    
    (h, w) = image.shape[:2]
    
    center = (w // 2, h // 2)
    
    # T·∫°o ma tr·∫≠n xoay v·ªõi g√≥c angle
    rotation_matrix = cv.getRotationMatrix2D(center, angle, 1.0)
    
    # Xoay ·∫£nh
    rotated_image = cv.warpAffine(image, rotation_matrix, (w, h))
    
    return rotated_image


def extract_SIFT_keypoints_and_descriptors(img):
    gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
    sift = cv.SIFT_create()
    kp, desc = sift.detectAndCompute(np.squeeze(gray_img), None)

    return kp, desc

def extract_ORB_keypoints_and_descriptors(img):
    gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
    orb = cv.ORB_create()
    kp, desc = orb.detectAndCompute(np.squeeze(gray_img), None)

    return kp, desc

def draw_keypoints_superpoint(image, keypoints):
    for keypoint in keypoints:
        x, y = int(keypoint[0]), int(keypoint[1])
        cv.circle(image, (x, y), radius=5, color=(0, 255, 0), thickness=2)  # M√†u xanh l√°
    st.image(image)
    return image

fe = SuperPointFrontend(weights_path = './services/semantic_keypoint_detection/superpoint_v1.pth', 
                            nms_dist = 4, 
                            conf_thresh = 0.015,
                            nn_thresh = 0.7,
                            cuda = False)

def extract_superpoint_keypoint_and_descriptor(img):
    
    # if os.path.exists('./services/semantic_keypoint_detection/superpoint_v1.pth'):
    #     print(1)
    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
    img_gray = img_gray.astype('float32')/255.0
    
    pts, desc, heatmap = fe.run(img_gray)
    # x_coords = pts[0, :]  
    # y_coords = pts[1, :]
    # keypoints = np.vstack((x_coords, y_coords)).T
    # keypoints = [cv.KeyPoint(p[0], p[1], 1) for p in keypoints]
    return pts, desc, heatmap

def convert_pts_to_keypoints(pts):
    keypoints = []
    for i in range(pts.shape[1]):
        # T·∫°o cv2.KeyPoint t·ª´ t·ªça ƒë·ªô (x, y) trong pts
        kp = cv.KeyPoint(x=pts[0, i], y=pts[1, i], size=1)
        keypoints.append(kp)
    return keypoints

def convert_pts_to_keypoints_gt(pts):
    keypoints = []
    for kp in pts:
        # T·∫°o cv2.KeyPoint t·ª´ t·ªça ƒë·ªô (x, y) trong pts
        kp = cv.KeyPoint(x=kp[0], y = kp[1], size=1)
        keypoints.append(kp)
    return keypoints

def match_descriptors(kp1, desc1, kp2, desc2):
    # Match the keypoints with the warped_keypoints with nearest neighbor search
    bf = cv.BFMatcher(cv.NORM_L2, crossCheck=True)
    if desc1 is None or desc2 is None:
        return None, None, None
    matches = bf.match(desc1, desc2)
    # print(type(desc1))
    matches_idx = np.array([m.queryIdx for m in matches])
    m_kp1 = [kp1[idx] for idx in matches_idx]
    matches_idx = np.array([m.trainIdx for m in matches])
    m_kp2 = [kp2[idx] for idx in matches_idx]

    return m_kp1, m_kp2, matches


def compute_homography(matched_kp1, matched_kp2):
    matched_pts1 = cv.KeyPoint_convert(matched_kp1)
    matched_pts2 = cv.KeyPoint_convert(matched_kp2)

    # Estimate the homography between the matches using RANSAC
    H, inliers = cv.findHomography(matched_pts1,
                                    matched_pts2,
                                    cv.RANSAC)
    inliers = inliers.flatten()
    return H, inliers


def preprocess_image(img_file, img_size):
    img = cv.imread(img_file, cv.IMREAD_COLOR)
    img = cv.resize(img, img_size)
    img_orig = img.copy()

    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
    img = np.expand_dims(img, 2)
    img = img.astype(np.float32)
    img_preprocessed = img / 255.

    return img_preprocessed, img_orig

def filter_keypoints_and_descriptors(keypoints_gt, keypoints_sift, descriptors_sift, max_distance=4):
    selected_keypoints = []
    selected_descriptors = []

    for gt_keypoint in keypoints_gt:
        
        gt_pt = np.array([gt_keypoint[1], gt_keypoint[0]])
        # T√≠nh kho·∫£ng c√°ch t·ª´ keypoint SIFT ƒë·∫øn keypoint ground truth
        distances = np.array([np.linalg.norm(np.array([kp.pt[0], kp.pt[1]]) - gt_pt) for kp in keypoints_sift])
        
        # L·∫•y c√°c keypoint SIFT c√≥ kho·∫£ng c√°ch nh·ªè h∆°n ho·∫∑c b·∫±ng max_distance
        valid_indices = np.where(distances <= max_distance)[0]
        
        if len(valid_indices) > 0:
            # N·∫øu c√≥ nhi·ªÅu keypoint th·ªèa m√£n, l·∫•y keypoint g·∫ßn nh·∫•t
            closest_index = valid_indices[np.argmin(distances[valid_indices])]
            selected_keypoints.append(keypoints_sift[closest_index])
            selected_descriptors.append(descriptors_sift[closest_index])

    # Chuy·ªÉn selected_descriptors th√†nh numpy array
    return selected_keypoints, np.array(selected_descriptors)

def select_indice_keypoint(image, keypoints_gt, keypoints_sift, max_distance=4):
    selected_indices = []
    selected_keypoints_groundtruth = []
    for gt_keypoint in keypoints_gt:
        
        gt_pt = np.array([gt_keypoint[1], gt_keypoint[0]])
        # T√≠nh kho·∫£ng c√°ch t·ª´ keypoint SIFT ƒë·∫øn keypoint ground truth
        distances = np.array([np.linalg.norm(np.array([kp.pt[0], kp.pt[1]]) - gt_pt) for kp in keypoints_sift])
        
        # L·∫•y c√°c keypoint SIFT c√≥ kho·∫£ng c√°ch nh·ªè h∆°n ho·∫∑c b·∫±ng max_distance
        valid_indices = np.where(distances <= max_distance)[0]
        if len(valid_indices) > 0:
            selected_keypoints_groundtruth.append(gt_pt)
            for indices in valid_indices:
                selected_indices.append(indices)
    return selected_indices, selected_keypoints_groundtruth

def compare_and_draw_sift_match(image_1, image_2, label):
    kp1, desc1 = extract_SIFT_keypoints_and_descriptors(image_1)
    sift_kp1, sift_desc1 = filter_keypoints_and_descriptors(label, kp1, desc1)
    sift_kp2, sift_desc2 = extract_SIFT_keypoints_and_descriptors(image_2)
    sift_m_kp1, sift_m_kp2, sift_matches = match_descriptors(
                sift_kp1, sift_desc1, sift_kp2, sift_desc2)
    if sift_m_kp1 is None and sift_m_kp2 is None and sift_matches is None:
        return image_1, 0.0
    if len(sift_m_kp1) < 4 or len(sift_m_kp2) < 4:
        # print(type(sift_m_kp1))
        return image_1, 0.0
    sift_H, sift_inliers = compute_homography(sift_m_kp1, sift_m_kp2)
    # Draw sift feature
    sift_matches = np.array(sift_matches)[sift_inliers.astype(bool)].tolist()
    sift_matched_img = cv.drawMatches(image_1, sift_kp1, image_2,
                                        sift_kp2, sift_matches, None,
                                        matchColor=(0, 255, 0),
                                        singlePointColor=(0, 0, 255))
    accuracy = len(sift_matches) / len(sift_kp1)
    return sift_matched_img, accuracy
    
def compare_and_draw_ORB_match(image_1, image_2, label):
    kp1, desc1 = extract_SIFT_keypoints_and_descriptors(image_1)
    sift_kp1, sift_desc1 = filter_keypoints_and_descriptors(label, kp1, desc1)
    sift_kp2, sift_desc2 = extract_SIFT_keypoints_and_descriptors(image_2)
    sift_kp2, sift_desc2 = extract_ORB_keypoints_and_descriptors(image_2)
    sift_m_kp1, sift_m_kp2, sift_matches = match_descriptors(
                sift_kp1, sift_desc1, sift_kp2, sift_desc2)
    if sift_m_kp1 is None and sift_m_kp2 is None and sift_matches is None:
        return image_1, 0.0
    if len(sift_m_kp1) < 4 or len(sift_m_kp2) < 4:
        return image_1, 0.0
    sift_H, sift_inliers = compute_homography(sift_m_kp1, sift_m_kp2)
    # Draw sift feature
    sift_matches = np.array(sift_matches)[sift_inliers.astype(bool)].tolist()
    sift_matched_img = cv.drawMatches(image_1, sift_kp1, image_2,
                                           sift_kp2, sift_matches, None,
                                           matchColor=(0, 255, 0),
                                           singlePointColor=(0, 0, 255))
    accuracy = len(sift_matches) / len(sift_kp1)
    return sift_matched_img, accuracy

def compare_and_draw_superpoint_match(image_1, image_2, label):
    image_kp1 = image_1.copy()
    image_gray = cv.cvtColor(image_kp1, cv.COLOR_BGR2GRAY)
    image_gray = image_gray.astype('float32') / 255.0
    pts1, desc_1 = fe.get_descriptor_from_keypoints(image_gray, label)
    pts2, desc_2, _ = extract_superpoint_keypoint_and_descriptor(image_2)
    kp1 = convert_pts_to_keypoints(pts1)
    kp2 = convert_pts_to_keypoints(pts2)
    desc1 = desc_1.T
    desc2 = desc_2.T
    # print(len(kp1), len(kp2))
    # print(desc_1.shape)
    # print(desc_2.shape)
    m_kp1, m_kp2, matches = match_descriptors(kp1, desc1, kp2, desc2)
    if m_kp1 is None and m_kp2 is None and matches is None:
        return image_1, 0.0
    if len(m_kp1) < 4 or len(m_kp2) < 4:
        return image_1, 0.0
    H, inliers = compute_homography(m_kp1, m_kp2)
    # Draw SuperPoint matches
    matches = np.array(matches)[inliers.astype(bool)].tolist()
    matched_img = cv.drawMatches(image_1, kp1, image_2, kp2, matches,
                                    None, matchColor=(0, 255, 0),
                                    singlePointColor=(0, 0, 255))
    accuracy = len(matches) / len(kp1)
    return matched_img, accuracy

def draw_true_keypoint(image, label, type):
    keypoints = 0
    desc = 0
    # type = 1: sift, 2: orb, 3: superpoint
    
    if type == 1:
        keypoints, desc = extract_SIFT_keypoints_and_descriptors(image)
    elif type == 2:
        keypoints, desc = extract_ORB_keypoints_and_descriptors(image)
    else:
        kp, desc = extract_superpoint_keypoint_and_descriptor(image)
        keypoints = convert_pts_to_keypoints(kp)
    id, pt_gt = select_indice_keypoint(image, label, keypoints)
    i = 0
    for kp in keypoints:
        x = int(kp.pt[0])
        y = int(kp.pt[1])
        if i in id:
            cv.circle(image, (x, y), radius=1, color=(0, 0, 255), thickness=2)
        else:
            cv.circle(image, (x, y), radius=1, color=(255, 0, 0), thickness=2)
        i += 1
    for kp in pt_gt:
        x = int(kp[0])
        y = int(kp[1])
        cv.circle(image, (x, y), radius=4, color= (0, 255, 0), thickness=2)
    return image

def plot_true_keypoint():
    path_dataset = './images/SIFT_SURF_ORB/synthetic_shapes_datasets/synthetic_shapes_datasets/'
    path = ['draw_checkerboard', 'draw_cube', 'draw_ellipses', 'draw_lines', 'draw_multiple_polygons',
                        'draw_polygon', 'draw_star', 'draw_stripes']
    name = ['checkerboard', 'cube', 'ellipses', 'lines', 'multiple_polygons', 'polygon', 'star', 'stripes']
    lst_image = []
    c = st.columns(4)
    for i in range(8):
        path_image = path_dataset + path[i] + "/" + "images/10.png"
        path_label = path_dataset + path[i] + "/" + "points/10.npy"
        image = cv.imread(path_image)
        label = np.load(path_label)
        draw_image = draw_true_keypoint(image, label, 1)
        c[i % 4].image(draw_image, caption=name[i])
    

def plot_keypoint_groundtruth():
    path_dataset = './images/SIFT_SURF_ORB/synthetic_shapes_datasets/synthetic_shapes_datasets/'
    path = ['draw_checkerboard', 'draw_cube', 'draw_ellipses', 'draw_lines', 'draw_multiple_polygons',
                        'draw_polygon', 'draw_star', 'draw_stripes']
    name = ['checkerboard', 'cube', 'ellipses', 'lines', 'multiple_polygons', 'polygon', 'star', 'stripes']
    lst_image = []
    c = st.columns(4)
    for i in range(8):
        path_image = path_dataset + path[i] + "/" + "images/33.png"
        path_label = path_dataset + path[i] + "/" + "points/33.npy"
        image = cv.imread(path_image)
        label = np.load(path_label)
        draw_image = draw_keypoints(image, label)
        c[i % 4].image(draw_image, caption=name[i])


def plot_sift():
    path_dataset = './images/SIFT_SURF_ORB/synthetic_shapes_datasets/synthetic_shapes_datasets/'
    path = ['draw_checkerboard', 'draw_cube', 'draw_ellipses', 'draw_lines', 'draw_multiple_polygons',
                        'draw_polygon', 'draw_star', 'draw_stripes']
    name = ['checkerboard', 'cube', 'ellipses', 'lines', 'multiple_polygons', 'polygon', 'star', 'stripes']
    lst_image = []
    c = st.columns(4)
    for i in range(8):
        path_image = path_dataset + path[i] + "/" + "images/90.png"
        image = cv.imread(path_image)
        kp, desc = extract_SIFT_keypoints_and_descriptors(image)
        draw_image = cv.drawKeypoints(image, kp, None, color=(0, 255, 0), flags=0)
        c[i % 4].image(draw_image, caption=name[i])

def plot_orb():
    path_dataset = './images/SIFT_SURF_ORB/synthetic_shapes_datasets/synthetic_shapes_datasets/'
    path = ['draw_checkerboard', 'draw_cube', 'draw_ellipses', 'draw_lines', 'draw_multiple_polygons',
                        'draw_polygon', 'draw_star', 'draw_stripes']
    name = ['checkerboard', 'cube', 'ellipses', 'lines', 'multiple_polygons', 'polygon', 'star', 'stripes']
    lst_image = []
    c = st.columns(4)
    for i in range(8):
        path_image = path_dataset + path[i] + "/" + "images/90.png"
        image = cv.imread(path_image)
        kp, desc = extract_ORB_keypoints_and_descriptors(image)
        draw_image = cv.drawKeypoints(image, kp, None, color=(0, 255, 0), flags=0)
        c[i % 4].image(draw_image, caption=name[i])


def example_conclusion_sift():
    path_dataset = './images/SIFT_SURF_ORB/synthetic_shapes_datasets/synthetic_shapes_datasets/'
    path = ['draw_checkerboard', 'draw_cube', 'draw_ellipses', 'draw_lines', 'draw_multiple_polygons',
                        'draw_polygon', 'draw_star', 'draw_stripes']
    name = ['checkerboard', 'cube', 'ellipses', 'lines', 'multiple_polygons', 'polygon', 'star', 'stripes']
    c = st.columns([2, 2, 2, 2])
    c[1].markdown("**Lines**")
    c[2].markdown("**Stripes**")
    
    for i in [3, 7]:
        path_image = path_dataset + path[i] + "/" + "images/103.png"
        path_label = path_dataset + path[i] + "/" + "points/103.npy"
        image = cv.imread(path_image)
        label = np.load(path_label)
        image_cpy = image.copy()
        draw_image_sift = draw_true_keypoint(image, label, 1)
        draw_image_orb = draw_true_keypoint(image_cpy, label, 2)
        if i == 3:
            c[1].image(draw_image_sift, caption="Keypoints of SIFT")
            c[1].image(draw_image_orb, caption="Keypoints of ORB")
            
        else:
            c[2].image(draw_image_sift, caption="Keypoints of SIFT")
            c[2].image(draw_image_orb, caption="Keypoints of ORB")

def example_conclusion_orb():
    path_dataset = './images/SIFT_SURF_ORB/synthetic_shapes_datasets/synthetic_shapes_datasets/'
    path = ['draw_checkerboard', 'draw_cube', 'draw_ellipses', 'draw_lines', 'draw_multiple_polygons',
                        'draw_polygon', 'draw_star', 'draw_stripes']
    name = ['checkerboard', 'cube', 'ellipses', 'lines', 'multiple_polygons', 'polygon', 'star', 'stripes']
    c = st.columns([2, 2, 2, 2, 2])
    c[0].markdown("**Checkerboard**")
    c[1].markdown("**Cube**")
    c[2].markdown("**Multiple polygons**")
    c[3].markdown("**Polygon**")
    c[4].markdown("**Star**")
    index = [0, 1, 4, 5, 6]
    for id in  range(len(index)):
        i = index[id]
        path_image = path_dataset + path[i] + "/" + "images/102.png"
        path_label = path_dataset + path[i] + "/" + "points/102.npy"
        image = cv.imread(path_image)
        label = np.load(path_label)
        image_cpy = image.copy()
        draw_image_sift = draw_true_keypoint(image, label, 1)
        draw_image_orb = draw_true_keypoint(image_cpy, label, 2)
        c[id].image(draw_image_orb, caption="Keypoints of ORB")
        c[id].image(draw_image_sift, caption="Keypoints of SIFT")
            
def example_conclusion_sift_and_orb():
    path_dataset = './images/SIFT_SURF_ORB/synthetic_shapes_datasets/synthetic_shapes_datasets/'
    path = ['draw_checkerboard', 'draw_cube', 'draw_ellipses', 'draw_lines', 'draw_multiple_polygons',
                        'draw_polygon', 'draw_star', 'draw_stripes']
    name = ['checkerboard', 'cube', 'ellipses', 'lines', 'multiple_polygons', 'polygon', 'star', 'stripes']
    c = st.columns([4, 2, 4])
    c[1].markdown("**Ellipse**")
    for i in [2]:
        path_image = path_dataset + path[i] + "/" + "images/103.png"
        path_label = path_dataset + path[i] + "/" + "points/103.npy"
        image = cv.imread(path_image)
        label = np.load(path_label)
        image_cpy = image.copy()
        draw_image_sift = draw_true_keypoint(image, label, 1)
        draw_image_orb = draw_true_keypoint(image_cpy, label, 2)
        c[1].image(draw_image_sift, caption="Keypoints of SIFT")
        c[1].image(draw_image_orb, caption="Keypoints of ORB")

def plot_compare_match():
    # lst_image, lst_label = get_image_with_100_percent()
    # rotate = [0, 10, 20, 30, 40]
    # lst_acc_sift = [[] for i in range(len(rotate))]
    # lst_acc_orb = [[] for i in range(len(rotate))]
    # for i in range(len(lst_image)):
    #     for j in range(len(rotate)):    
    #         image_1 = lst_image[i]
    #         image_2 = rotate_image(image_1, rotate[j])
    #         image_sift, acc_sift = compare_and_draw_sift_match(image_1, image_2)
    #         image_orb, acc_orb = compare_and_draw_ORB_match(image_1, image_2)
    #         if acc_sift != 0.0 and acc_orb != 0.0:
    #             lst_acc_sift[j].append(acc_sift)
    #             lst_acc_orb[j].append(acc_orb)
    # average_acc_sift = []
    # average_acc_orb = []
    # for i in range(len(rotate)):
    #     average_acc_sift.append(sum(lst_acc_sift[i]) / len(lst_acc_sift[i]))
    #     average_acc_orb.append(sum(lst_acc_orb[i]) / len(lst_acc_orb[i]))
    # # print(average_acc_sift[0], average_acc_orb[0])
    pickle_file_average_acc_sift = './data_processed/Semantic_Keypoint_Detection/avg_acc_sift.pkl'
    # with open(pickle_file_average_acc_sift, 'wb') as file:
    #     pickle.dump(average_acc_sift, file)
    
    pickle_file_average_acc_orb = './data_processed/Semantic_Keypoint_Detection/avg_acc_orb.pkl'
    # with open(pickle_file_average_acc_orb, 'wb') as file:
    #     pickle.dump(average_acc_orb, file)
    # average_acc_sift = []
    # average_acc_orb = []
    # with open(pickle_file_average_acc_sift, 'rb') as file:
    #     average_acc_sift = pickle.load(file)
    
    # with open(pickle_file_average_acc_orb, 'rb') as file:
    #     average_acc_orb = pickle.load(file)
    # degree_symbol = "\u00B0"
    # categories = [f'0{degree_symbol}', f'10{degree_symbol}', f'20{degree_symbol}', f'30{degree_symbol}', f'40{degree_symbol}']
    # values1 = np.array(average_acc_sift)
    # values2 = np.array(average_acc_orb)
    
    # x = np.arange(len(categories))  
    # width = 0.35 

    # fig, ax = plt.subplots()
    # rects1 = ax.bar(x - width/2, values1, width, label='Accuracy of SIFT match')
    # rects2 = ax.bar(x + width/2, values2, width, label='Accuracy of ORB match')

    # ax.set_ylabel('Average Accuracy')
    # ax.set_title('Bi·ªÉu ƒë·ªì so s√°nh Average Accuracy khi √°p d·ª•ng thu·∫≠t to√°n SIFT v√† ORB')
    # ax.set_xticks(x)
    # ax.set_xticklabels(categories)
    # ax.legend()

    # c = st.columns([2, 6, 2])
    # c[1].pyplot(fig)

def get_image_with_100_percent():
    # lst_image = []
    # lst_label = []
    # with open('./data_processed/Semantic_Keypoint_Detection/lst_image.pkl', 'rb') as file:
    #     lst_image = pickle.load(file)
    # with open('./data_processed/Semantic_Keypoint_Detection/lst_label.pkl', 'rb') as file:
    #     lst_label = pickle.load(file)
    lst_image, lst_label = get_image_and_label()
    lst_best_image = []
    lst_best_label = []
    for i in range(len(lst_image)):
        for j in range(len(lst_image[i])):
            keypoints, _, _ = SIFT_result(lst_image[i][j])
            
            keypoints_ORB, _, image = ORB_result(lst_image[i][j])
            
            precision_sift = calculate_precision(keypoints, lst_label[i][j], threshold=4)
            recall_sift = calculate_recall(keypoints, lst_label[i][j], threshold=4)
            
            precision_orb = calculate_precision(keypoints_ORB, lst_label[i][j], threshold=4)
            recall_orb = calculate_recall(keypoints_ORB, lst_label[i][j], threshold=4)
            if (precision_sift == 1.0) or (precision_orb == 1.0) or (recall_sift == 1.0) or (recall_orb == 1.0):
                lst_best_image.append(lst_image[i][j])
                lst_best_label.append(lst_label[i][j])
    return lst_best_image, lst_best_label

def result_of_match():
    # lst_image = get_image_with_100_percent()
    # pickle_image_100_percent = './data_processed/Semantic_Keypoint_Detection/image_100_percent.pkl'
    # with open(pickle_image_100_percent, 'wb') as file:
    #     pickle.dump(lst_image, file)
    # angel = [0, 10, 20, 30, 40]
    # result_image_sift = []
    # result_image_orb = []
    # for i in range(len(angel)):
    #     image_1 = lst_image[2]
    #     image_2 = rotate_image(image_1, angel[i])
    #     image_sift, acc_sift = compare_and_draw_sift_match(image_1, image_2)
    #     image_orb, acc_orb = compare_and_draw_ORB_match(image_1, image_2)
    #     result_image_sift.append((image_sift, acc_sift))
    #     result_image_orb.append((image_orb, acc_orb))
    #     c[0].image(image_sift)
    #     c[0].markdown(f"<div style='text-align: center;'><b>Accuracy = {acc_sift:.2f}</b></div>", unsafe_allow_html=True)
        
    #     c[1].image(image_orb)
    #     c[1].markdown(f"<div style='text-align: center;'><b>Accuracy = {acc_orb:.2f}</b></div>", unsafe_allow_html=True)

        
    # for i in range(len(angel)):
    #     image_1 = lst_image[861]
    #     image_2 = rotate_image(image_1, angel[i])
    #     image_sift, acc_sift = compare_and_draw_sift_match(image_1, image_2)
    #     image_orb, acc_orb = compare_and_draw_ORB_match(image_1, image_2)
    #     result_image_sift.append((image_sift, acc_sift))
    #     result_image_orb.append((image_sift, acc_orb))
    #     c[3].image(image_sift)
    #     c[3].markdown(f"<div style='text-align: center;'><b>Accuracy = {acc_sift:.2f}</b></div>", unsafe_allow_html=True)
        
    #     c[4].image(image_orb)
    #     c[4].markdown(f"<div style='text-align: center;'><b>Accuracy = {acc_orb:.2f}</b></div>", unsafe_allow_html=True)
    pickle_sift_match_ex = './data_processed/Semantic_Keypoint_Detection/sift_match_example.pkl'
    # with open(pickle_sift_match_ex, 'wb') as file:
    #     pickle.dump(result_image_sift, file)   
    
    pickle_orb_match_ex = './data_processed/Semantic_Keypoint_Detection/orb_match_example.pkl'
    # with open(pickle_orb_match_ex, 'wb') as file:
    #     pickle.dump(result_image_orb, file)  
    
    degree_symbol = "\u00B0"
    angel = [0, 10, 20, 30, 40]
    result_image_sift = []
    result_image_orb = []
    with open(pickle_sift_match_ex, 'rb') as file:
        result_image_sift = pickle.load(file)
    with open(pickle_orb_match_ex, 'rb') as file:
        result_image_orb = pickle.load(file)
    n = len(angel)
    for i in range(n):
        c = st.columns([3, 3, 1, 3, 3])
        image_1, acc_1 = result_image_sift[i]
        image_3, acc_3 = result_image_sift[i + n]
        
        image_2, acc_2 = result_image_orb[i]
        image_4, acc_4 = result_image_orb[i + n]
        c[0].image(image_1)
        c[0].markdown(f"<div style='text-align: center;'><b>Accuracy = {acc_1:.2f}</b></div>", unsafe_allow_html=True)
        
        c[1].image(image_2)
        c[1].markdown(f"<div style='text-align: center;'><b>Accuracy = {acc_2:.2f}</b></div>", unsafe_allow_html=True)

        c[2].markdown(
            f"""
            <div style='display: flex; align-items: center; justify-content: center; height: 100%; font-weight: bold;'>
                {str(angel[i])} {degree_symbol}
            </div>
            """,
            unsafe_allow_html=True
        )
        
        c[3].image(image_3)
        c[3].markdown(f"<div style='text-align: center;'><b>Accuracy = {acc_3:.2f}</b></div>", unsafe_allow_html=True)
        
        c[4].image(image_4)
        c[4].markdown(f"<div style='text-align: center;'><b>Accuracy = {acc_4:.2f}</b></div>", unsafe_allow_html=True)
        


def Text_of_App():
    st.header("1. Gi·ªõi thi·ªáu Synthetic shapes datasets")
    st.write("Dataset **Synthetic shapes datasets** g·ªìm $8$ class ·∫£nh v·ªÅ h√¨nh h·ªçc bao g·ªìm ·∫£nh v√† t·ªça ƒë·ªô c√°c keypoint c·ªßa t·ª´ng ·∫£nh nh∆∞:")
    st.write("  -  **Draw checkerboard, Draw cube, Draw ellipses, Draw lines, Draw multiple polygon, Draw polygon, Draw star v√† Draw stripes**")
    st.write("  - M·ªói class c√≥ $500$ ·∫£nh v√† t·ªïng s·ªë ·∫£nh trong dataset l√† $4000$ ·∫£nh")
    st.write("**M·ªôt s·ªë ·∫£nh trong Dataset v√† c√°c keypoint t∆∞∆°ng ·ª©ng**")
    # path_dataset = './images/SIFT_SURF_ORB/dataset_with_keypoint.PNG'
    plot_keypoint_groundtruth()
    # image_dataset = cv.imread(path_dataset)
    # c = st.columns([2, 6, 2])
    # c[1].image(image_dataset,channels="BGR")
    st.header("2. Ph∆∞∆°ng ph√°p")
    st.markdown("### 2.1 SIFT")
    
    st.markdown("#### 2.1.1 Gi·ªõi thi·ªáu v·ªÅ thu·∫≠t to√°n SIFT" )
    st.write("Thu·∫≠t to√°n **SIFT (Scale-Invariant Feature Transform)** ph√°t hi·ªán v√† m√¥ t·∫£ c√°c ƒëi·ªÉm ƒë·∫∑c tr∆∞ng **(keypoints)** trong ·∫£nh m·ªôt c√°ch kh√¥ng thay ƒë·ªïi tr∆∞·ªõc bi·∫øn ƒë·ªïi t·ª∑ l·ªá, g√≥c quay, v√† c∆∞·ªùng ƒë·ªô √°nh s√°ng")
    st.write("Thu·∫≠t to√°n **SIFT** ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi **David Lowe**, v√† b√†i b√°o g·ªëc m√¥ t·∫£ **SIFT** l√†:")
    st.write("  - **Lowe, David G. ""Distinctive image features from scale-invariant keypoints."" International Journal of Computer Vision, 2004.**")
    st.write(" B√†i b√°o n√†y ƒë∆∞·ª£c tr√≠ch d·∫´n r·ªông r√£i v√† l√† n·ªÅn t·∫£ng cho nhi·ªÅu ·ª©ng d·ª•ng v√† nghi√™n c·ª©u v·ªÅ th·ªã gi√°c m√°y t√≠nh.")
    st.markdown("#### 2.1.2 Thu·∫≠t to√°n SIFT")
    c = st.columns(2)
    with c[0]:
        st.markdown(
                """
                C√°c b∆∞·ªõc ch√≠nh c·ªßa thu·∫≠t to√°n SIFT:
                1. **Ph√°t hi·ªán ƒëi·ªÉm ƒë·∫∑c tr∆∞ng:** S·ª≠ d·ª•ng **Difference of Gaussian (DoG)** tr√™n c√°c phi√™n b·∫£n ·∫£nh v·ªõi nhi·ªÅu m·ª©c t·ª∑ l·ªá ƒë·ªÉ t√¨m ƒëi·ªÉm c·ª±c tr·ªã.
                2. **L·ªçc ƒëi·ªÉm y·∫øu:** Lo·∫°i b·ªè c√°c ƒëi·ªÉm kh√¥ng ·ªïn ƒë·ªãnh.
                3. **X√°c ƒë·ªãnh h∆∞·ªõng:** T√≠nh to√°n g√≥c gradient ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng thay ƒë·ªïi ƒë·ªëi v·ªõi vi·ªác xoay ·∫£nh.
                4. **T·∫°o descriptor:** M√¥ t·∫£ ƒëi·ªÉm d·ª±a tr√™n gradient c∆∞·ªùng ƒë·ªô xung quanh.
                5. **So kh·ªõp ƒë·∫∑c tr∆∞ng:** D√πng kho·∫£ng c√°ch gi·ªØa c√°c **descriptor** ƒë·ªÉ gh√©p ƒëi·ªÉm t·ª´ c√°c ·∫£nh kh√°c nhau.
                """)
    with c[1]:
        st.write("D∆∞·ªõi ƒë√¢y l√† h√¨nh ·∫£nh minh h·ªça thu·∫≠t to√°n **SIFT**:")
        st.image('./images/SIFT_SURF_ORB/sift_algorith.png', channels="BGR", width=500)
    st.write("Du·ªõi ƒë√¢y l√† k·∫øt qu·∫£ c·ªßa m·ªôt s·ªë ·∫£nh khi √°p d·ª•ng thu·∫≠t to√°n **SIFT**")
    plot_sift()

    st.markdown("### 2.2 ORB")
    st.markdown("#### 2.2.1 Gi·ªõi thi·ªáu v·ªÅ thu·∫≠t to√°n ORB")
    st.write("**ORB (Oriented FAST and Rotated BRIEF)** l√† thu·∫≠t to√°n ph√°t hi·ªán v√† m√¥ t·∫£ ƒë·∫∑c tr∆∞ng h√¨nh ·∫£nh, "
            + "ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi c√°c nh√† nghi√™n c·ª©u **Ethan Rublee, Vincent Rabaud, Kurt Konolige, v√† Gary R. Bradski** v√† ƒë∆∞·ª£c gi·ªõi thi·ªáu l·∫ßn ƒë·∫ßu ti√™n v√†o nƒÉm $2011$ trong b√†i b√°o sau:")
    st.write("  - **Rublee, Ethan, et al. ""ORB: An efficient alternative to SIFT or SURF."" 2011 International Conference on Computer Vision (ICCV). IEEE, 2011.**")
    st.write("**ORB** ƒë∆∞·ª£c thi·∫øt k·∫ø nh∆∞ m·ªôt thu·∫≠t to√°n ph√°t hi·ªán v√† m√¥ t·∫£ ƒë·∫∑c tr∆∞ng nhanh v√† hi·ªáu qu·∫£ h∆°n, thay th·∫ø cho c√°c thu·∫≠t to√°n **SIFT** v√† **SURF**, v·ªõi t√≠nh b·∫•t bi·∫øn theo g√≥c xoay v√† t·ª∑ l·ªá.")
    st.markdown("#### 2.2.2 Thu·∫≠t to√°n ORB")
    c = st.columns(2)
    with c[0]:
        st.markdown(
                """
                **C√°c b∆∞·ªõc ch√≠nh c·ªßa thu·∫≠t to√°n ORB:**
                1. **Ph√°t hi·ªán keypoints:** D√πng **FAST** ƒë·ªÉ t√¨m ƒëi·ªÉm ƒë·∫∑c tr∆∞ng v√† **Harris** ƒë·ªÉ ch·ªçn ƒëi·ªÉm t·ªët nh·∫•t.
                2. **X√°c ƒë·ªãnh h∆∞·ªõng:** T√≠nh to√°n h∆∞·ªõng gradient ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng thay ƒë·ªïi khi xoay.
                3. **M√¥ t·∫£ ƒë·∫∑c tr∆∞ng:** S·ª≠ d·ª•ng **BRIEF** v·ªõi s·ª± ƒëi·ªÅu ch·ªânh theo h∆∞·ªõng keypoint ƒë·ªÉ t·∫°o descriptor.
                4. **So kh·ªõp:** D√πng kho·∫£ng c√°ch Hamming ƒë·ªÉ so kh·ªõp descriptor gi·ªØa c√°c ·∫£nh.
                """)
    with c[1]:
        st.write("D∆∞·ªõi ƒë√¢y l√† h√¨nh ·∫£nh minh h·ªça thu·∫≠t to√°n ORB")
        st.image('./images/SIFT_SURF_ORB/achitecture_of_ORB.png', channels="BGR", width=480)
    st.write("D∆∞·ªõi ƒë√¢y l√† k·∫øt qu·∫£ c·ªßa m·ªôt s·ªë ·∫£nh khi √°p d·ª•ng thu·∫≠t to√°n **ORB**")
    plot_orb()

    st.header("3. ƒê√°nh gi√°")
    st.write("  - Ti·∫øn h√†nh ƒë√°nh gi√° tr√™n 2 ƒë·ªô ƒëo **Precision** v√† **Recall** khi √°p d·ª•ng **SIFT v√† ORB**")
    c1, c2, c3 = st.columns([1, 8, 1])
    c2.image('./images/SIFT_SURF_ORB/precision_and_recall.png', channels="BGR", width=500)
    st.markdown(
                """
                - **Keypoint** ƒë√≥ ƒë∆∞·ª£c cho l√† d·ª± ƒëo√°n ƒë√∫ng n·∫øu kho·∫£ng c√°ch **Euclidean** c·ªßa **Keypoint** ƒë√≥ so v·ªõi kho·∫£ng c√°ch c·ªßa **Keypoint** th·ª±c t·∫ø <= **Threshold**
                    - $d(groundtruth, predict) = \sqrt{(x_{groundtruth} - x_{predict}) ^ 2 + (y_{groundtruth} - y_{predict}) ^ 2}$
                    - $d(groundtruth, predict)$ <= **Threshold**
                    - **Trong ƒë√≥:**
                        - **Threshold** = $4$
                        - **groundtruth** l√† **keypoint groundtruth**
                        - **predict** l√† **keypoint predict**
                """)
    # st.markdown("   - C√¥ng th·ª©c kho·∫£ng c√°ch **Euclidean:**")
    # c = st.columns([2, 6, 2])
    # c[1].image('./images/SIFT_SURF_ORB/euclidean.png',channels="BGR", width=300)
    st.markdown("D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë v√≠ d·ª• v·ªÅ c√°c **Keypoints** ƒë∆∞·ª£c d·ª± ƒëo√°n ƒë√∫ng")
    plot_true_keypoint()
    st.header("4. K·∫øt qu·∫£")
    st.markdown("D∆∞·ªõi ƒë√¢y l·∫ßn l∆∞·ª£t l√† 2 bi·ªÉu ƒë·ªì so s√°nh **Precision** v√† **Recall** c·ªßa Thu·∫≠t to√°n **SIFT** v√† **ORB**")
    plot_metric()
    st.header("5. Th·∫£o lu·∫≠n")
    st.markdown("**Nh·∫≠n x√©t t·ªïng quan:**")
    st.write("  - **ORB** nh√¨n chung c√≥ **Precision** v√† **Recall** cao h∆°n cho c√°c h√¨nh d·∫°ng c√≥ ƒë·∫∑c tr∆∞ng n·ªïi b·∫≠t, d·ªÖ ph√°t hi·ªán v√† ph√¢n bi·ªát.")
    st.write("  - **SIFT** l·∫°i ho·∫°t ƒë·ªông t·ªët h∆°n tr√™n c√°c h√¨nh d·∫°ng c√≥ chi ti·∫øt ƒë∆°n gi·∫£n ho·∫∑c ƒë·ªÅu ƒë·∫∑n, nh∆∞ **Lines** v√† **Stripes**.")
    st.markdown("**Nh·∫≠n x√©t v√† gi·∫£i th√≠ch:**")
    st.write("  - **ORB** c√≥ ƒë·ªô ch√≠nh x√°c v√† ƒë·ªô bao ph·ªß t·ªët h∆°n cho m·ªôt s·ªë h√¨nh d·∫°ng c√≥ ƒë·∫∑c tr∆∞ng ph√¢n bi·ªát r√µ r√†ng nh∆∞ **Checkerboard, Cube, Multiple polygons, Polygon**, v√† **Star**, do **ORB** t·ªëi ∆∞u cho vi·ªác ph√°t hi·ªán ƒë·∫∑c tr∆∞ng nhanh "
             + "v√† √≠t ch·ªãu ·∫£nh h∆∞·ªüng t·ª´ thay ƒë·ªïi g√≥c xoay. Do ƒë√≥ **Precision** v√† **Recall** c·ªßa **ORB** cao h∆°n **SIFT**")
    example_conclusion_orb()
    st.write("  - **SIFT** ho·∫°t ƒë·ªông t·ªët h∆°n tr√™n c√°c h√¨nh d·∫°ng ƒë∆°n gi·∫£n, tu·∫ßn ho√†n nh∆∞ **Lines** v√† **Stripes** v√¨ n√≥ c√≥ c√°ch ti·∫øp c·∫≠n chi ti·∫øt trong vi·ªác ph√°t hi·ªán ƒë·∫∑c tr∆∞ng, ph√π h·ª£p v·ªõi nh·ªØng chi ti·∫øt nh·ªè c·ªßa h√¨nh d·∫°ng n√†y n√™n "
             + "**Precision** v√† **Recall** c·ªßa **SIFT** cao h∆°n **ORB**")
    example_conclusion_sift()
    st.write("  - **Ellipses**: C·∫£ hai thu·∫≠t to√°n ƒë·ªÅu c√≥ **Precision** v√† **Recall** th·∫•p cho c√°c h√¨nh d·∫°ng n√†y, do ch√∫ng c√≥ √≠t ƒë·∫∑c tr∆∞ng n·ªïi b·∫≠t ho·∫∑c qu√° ph·ª©c t·∫°p ƒë·ªÉ c√°c thu·∫≠t to√°n n√†y d·ªÖ d√†ng ph√°t hi·ªán.")
    example_conclusion_sift_and_orb()

def Text_of_Superpoint_rotation():
    dg = "\u00B0"
    st.header("1. Thi·∫øt l·∫≠p th√≠ nghi·ªám")
    st.markdown("""
                - Ti·∫øn h√†nh th√≠ nghi·ªám ƒë·ªëi v·ªõi nh·ªØng ·∫£nh trong t·∫≠p **Synthetic Shapes Dataset** m√† **SIFT** ho·∫∑c **ORB** ƒë·∫°t **100%** v·ªÅ ph√°t hi·ªán **Keypoints** (theo **Ground Truth**)
                    - S·ªë l∆∞·ª£ng ·∫£nh t√¨m ƒë∆∞·ª£c: $1147$ ·∫£nh 
                """)
    
    st.markdown(f"""
                - Th·ª±c hi·ªán th√≠ nghi·ªám ƒë√°nh gi√° **SIFT, ORB** tr√™n ti√™u ch√≠ **rotation** (g√≥c quay **0{dg}, 10{dg}, 20{dg}, 30{dg}, 40{dg}**) ƒë·ªÉ ƒë√°nh gi√° m·ª©c ƒë·ªô **matching keypoints** c·ªßa 2 ph∆∞∆°ng ph√°p tr√™n t·∫≠p d·ªØ li·ªáu v·ª´a t√¨m ƒë∆∞·ª£c ·ªü tr√™n.
                    - S·ª≠ d·ª•ng ƒë·ªô ƒëo ƒë·ªÉ ƒë√°nh gi√°: **Accuracy**
                """)
    c = st.columns([2, 6, 2])
    c[1].image('./images/SIFT_SURF_ORB/accuracy.png', channels="BGR", width=400)
    
    st.header("2. K·∫øt qu·∫£")
    st.write(f" - D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë h√¨nh ·∫£nh **matching keypoints** c·ªßa 2 h√¨nh ·∫£nh khi 1 ·∫£nh gi·ªØ nguy√™n v√† 1 ·∫£nh xoay m·ªôt g√≥c **0{dg}, 10{dg}, 20{dg}, 30{dg}, 40{dg}** c·ªßa thu·∫≠t to√°n **SIFT** v√† **ORB**")
    c = st.columns([3, 3, 1, 3, 3])
    c[0].markdown(f"<div style='text-align: center;'><b>SIFT</b></div>", unsafe_allow_html=True)
    c[1].markdown(f"<div style='text-align: center;'><b>ORB</b></div>", unsafe_allow_html=True)
    c[2].markdown(f"<div style='text-align: center;'><b>Rotation</b></div>", unsafe_allow_html=True)
    c[3].markdown(f"<div style='text-align: center;'><b>SIFT</b></div>", unsafe_allow_html=True)
    c[4].markdown(f"<div style='text-align: center;'><b>ORB</b></div>", unsafe_allow_html=True)
    result_of_match()
    st.write("  - Du·ªõi ƒë√¢y l√† bi·ªÉu ƒë·ªì bi·ªÉu di·ªÖn **Average Accuracy** c·ªßa khi √°p d·ª•ng thu·∫≠t to√°n **SIFT** v√† **ORB**")
    plot_compare_match()
    st.header("3. Th·∫£o lu·∫≠n")
    st.markdown("#### 3.1 Nh·∫≠n x√©t")
    st.write("  - ƒê·ªô ch√≠nh x√°c c·ªßa c·∫£ hai thu·∫≠t to√°n gi·∫£m ƒë√°ng k·ªÉ khi g√≥c quay tƒÉng.")
    st.write("  - **SIFT**: M·∫∑c d√π gi·∫£m nh∆∞ng v·∫´n gi·ªØ ƒë∆∞·ª£c ƒë·ªô ch√≠nh x√°c cao h∆°n **ORB** trong t·∫•t c·∫£ c√°c g√≥c quay.")
    st.write("  - **ORB**: ƒê·ªô ch√≠nh x√°c gi·∫£m nhanh h∆°n so v·ªõi **SIFT** khi g√≥c quay tƒÉng, th·ªÉ hi·ªán r·∫±ng **ORB** c√≥ th·ªÉ nh·∫°y c·∫£m h∆°n v·ªõi c√°c g√≥c quay l·ªõn.")
    st.markdown("#### 3.2 Gi·∫£i th√≠ch")
    st.markdown("""
                - **SIFT** c√≥ kh·∫£ nƒÉng ch·ªãu ƒë∆∞·ª£c s·ª± thay ƒë·ªïi g√≥c quay t·ªët h∆°n ORB, ƒëi·ªÅu n√†y c√≥ th·ªÉ do **SIFT** kh√¥ng ch·ªâ d·ª±a v√†o c√°c ƒë·∫∑c tr∆∞ng v·ªÅ c∆∞·ªùng ƒë·ªô 
                m√† c√≤n s·ª≠ d·ª•ng **gradient** h∆∞·ªõng ƒë·ªÉ x√°c ƒë·ªãnh **keypoint**, t·ª´ ƒë√≥ gi√∫p duy tr√¨ ƒë·ªô ·ªïn ƒë·ªãnh khi c√≥ s·ª± thay ƒë·ªïi g√≥c quay.
                """)
    st.markdown("""
                - **ORB** c√≥ xu h∆∞·ªõng k√©m ·ªïn ƒë·ªãnh h∆°n khi c√≥ s·ª± thay ƒë·ªïi v·ªÅ g√≥c quay, ƒëi·ªÅu n√†y l√†m gi·∫£m ƒë·ªô ch√≠nh x√°c c·ªßa n√≥ nhanh h∆°n so v·ªõi **SIFT**.
                """
                )
def App():
    tab = st.tabs(["**Sematic Keypoint Detection**", "**Superpoint - Rotation**"])
    with tab[0]:
        Text_of_App()
    with tab[1]:
        Text_of_Superpoint_rotation()
        # extract_superpoint_keypoint_and_descriptor()
        
App()